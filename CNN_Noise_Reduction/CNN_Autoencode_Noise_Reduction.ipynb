{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 10  # how many records we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "# The encoding process\n",
    "input_img = Input(shape=(28, 28, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# Encoding #\n",
    "############\n",
    "# Note:\n",
    "# padding is a hyper-arameter for either 'valid' or 'same'. \n",
    "# \"valid\" means \"no padding\". \n",
    "# \"same\" results in padding the input such that the output has the same length as the original input.\n",
    "\n",
    "# Conv1 #\n",
    "x = Conv2D(filters = 16, kernel_size = (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D(pool_size = (2, 2), padding='same')(x)\n",
    "\n",
    "# Conv2 #\n",
    "x = Conv2D(filters = 8, kernel_size = (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size = (2, 2), padding='same')(x) \n",
    "\n",
    "# Conv 3 #\n",
    "x = Conv2D(filters = 8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D(pool_size = (2, 2), padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "############\n",
    "# Decoding #\n",
    "############\n",
    "\n",
    "# DeConv1\n",
    "x = Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "# DeConv2\n",
    "x = Conv2D(filters=8, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D(size=(2, 2))(x)\n",
    "\n",
    "# DeConv3\n",
    "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "\n",
    "decoded = Conv2D(filters=1, kernel_size=(3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Decalre the Model\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_8 to have 4 dimensions, but got array with shape (10000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-2abc63b4d046>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    970\u001b[0m                 \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 972\u001b[1;33m                 batch_size=batch_size)\n\u001b[0m\u001b[0;32m    973\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                 \u001b[0mval_ins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_x\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_y\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_8 to have 4 dimensions, but got array with shape (10000, 28, 28)"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "x_train=x_train.reshape([-1,28, 28,1])\n",
    "autoencoder.fit(x_train, x_train, epochs=100, batch_size=128, shuffle=True, validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_7 to have 4 dimensions, but got array with shape (10000, 28, 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-d89f58cffb47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdecoded_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1147\u001b[0m                              'argument.')\n\u001b[0;32m   1148\u001b[0m         \u001b[1;31m# Validate user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    126\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    129\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_7 to have 4 dimensions, but got array with shape (10000, 28, 28)"
     ]
    }
   ],
   "source": [
    "decoded_images = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original \n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # display reconstruction \n",
    "    ax = plt.subplot(2, n, i+1+n)\n",
    "    plt.imshow(decoded_images[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
